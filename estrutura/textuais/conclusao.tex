% CONCLUSÃO--------------------------------------------------------------------

\chapter{CONCLUSÃO}
\label{chap:conclusao}

A tarefa de classificação de imagem vem sendo um dos grandes desafios na área de visão computacional. Utilizar \textit{deep learning}, com CNN, para a classificação de imagens é algo que ocorre desde 2012 e vem atualizando o estado da arte nessa área. Neste trabalho utilizamos de CNN para realizar a classificação de imagens de comida, utilizando técnicas de \textit{data augmentation} e inicialização dos pesos da rede para obter uma melhor classificação e reduzir o \textit{overfitting}, uns dos grandes problemas no uso de CNN. A rede neural \textit{AlexNet}, desenvolvida por \citeonline{imaginetArticle}, serviu de base para o desenvolvimento da CNN proposta

\par Foram executados experimentos com a CNN propostas, foi utilizada uma base de dados formulada a partir das bases de imagens \textit{ImageNet}\cite{deng2009imagenet} e \textit{Food-101}\cite{bossard14}. A base formulada apresenta 16 classes, representadas em 16.000 imagens (1.000 imagens cada classe). O resultado apresentado pelo modelo inicial sem as melhorias foi de 53,6\%, evidenciando o problema (\textit{overfitting}) que gera ao possuir uma quantidade pequena de amostras para a etapa de treino, na qual foram utilizadas 700 imagens de cada classe para o treino.

\par Com a aplicação do \textit{data augmentation} na base foi obtida uma redução no significativa no \textit{overfitting}, mas não apresentou uma melhora expressiva na tarefa de classificação. Aplicando a técnica de inicialização dos pesos com os valores obtidos a partir de um rede já treinada, em conjunto com o \textit{data augmentation}, resultou em uma melhora considerável na classificação com 71,77\% de acurácia, porém apresentava \textit{overfitting}.

\par Assim, foram realizados experimentos para a otimização da taxa de \textit{dropout}, conseguindo então obter o melhor resultado entre todos os modelos. A taxa de \textit{dropout} em 80\% resultou em uma acurácia na classificação de 74,56\%, sendo o experimento que apresentou o melhor resultado. Nesse experimento, também foi mostrou uma pequena melhora na redução do \textit{overfitting}.

\par Como relatado por trabalhos anteriores e apresentado nesse trabalho, o emprego da técnica de \textit{data augmentation} obteve um resultado expressivo para realizar a redução do \textit{overfitting}, além de proporcionar uma ligeira melhora na classificação. A aplicação em conjunto do \textit{data augmentation}, inicialização dos pesos e otimização da taxa de \textit{dropout} (74,56\%), apresentou um aumento em 20,96\% na acurácia, se comparado com o modelo proposto sem as melhorias (53,6\% de acurácia).

\par Outra abordagem que pode ser realizada futuramente é utilizar o modelo para aplicar a extração das características em conjunto com outro classificador como SVM (do inglês \textit{suport vector machine}) para realizar a predição. A aplicação de vetores de dissimilaridade nas características extraídas com a CNN para a classificação seria outro caminho a ser abordado. Otimizações de outros parâmetros da rede, como a taxa de aprendizagem, e o estudo de outras arquiteturas de CNN, como a \textit{GoogLeNet} \cite{szegedy2015going}, para incrementar novas opções de arquitetura de CNN no modelo proposto. A aplicação de técnicas para redução dos parâmetros, possibilitaria o uso desse classificador em dispositivos com uma menor capacidade de processamento.